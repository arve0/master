<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
</head>
<body>
<div id="TOC">
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#theory">Theory</a><ul>
<li><a href="#leica-software">Leica software</a></li>
<li><a href="#image-processing">Image Processing</a></li>
</ul></li>
<li><a href="#method">Method</a><ul>
<li><a href="#microscope">Microscope</a></li>
<li><a href="#automated-scanning">Automated scanning</a><ul>
<li><a href="#overview-images">Overview images</a></li>
<li><a href="#shg-images">SHG images</a></li>
<li><a href="#dapi-images">DAPI images</a></li>
</ul></li>
<li><a href="#correlating-images-with-patient-data">Correlating images with patient data</a></li>
<li><a href="#collection-of-shg-images">Collection of SHG images</a></li>
<li><a href="#technical-details">Technical details</a><ul>
<li><a href="#hardware-aspects">Hardware aspects</a></li>
<li><a href="#leica-software-details">Leica software details</a></li>
<li><a href="#software-development">Software development</a></li>
</ul></li>
</ul></li>
<li><a href="#result">Result</a><ul>
<li><a href="#segmentation-1">Segmentation</a></li>
</ul></li>
<li><a href="#discussion">Discussion</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#appendix">Appendix</a><ul>
<li><a href="#slidemaperrors">Slide map errors</a></li>
</ul></li>
</ul>
</div>
<h1 id="abstract">Abstract</h1>
<p>What to communicate: goal, overview of experiences made, results</p>
<p>This thesis documents work on automatic microscope imaging of breast tumor tissue micro arrays and how the images can be analyzed for a supplement in cancer diagnosis. The overall research goal has been to classify tumor grade (I, II or III) based on the fiber structure in the tissue samples. Supervised machine learning is the method of analysis, where St. Olavs hospital has supplied a dataset of tissue samples at the tumor peripheral from 924 (TODO update excact number) patients.</p>
<p>Automated microscope scanning is in principle straight forward, but the implementation will be dependent on many aspects of the experimental setup. In general, some of the aspects discussed in this thesis are:</p>
<ul>
<li>correcting for systematic errors like intensity variations</li>
<li>create image analysis algorithms that are robust to experimental variations</li>
<li>verify that metrics reported by the system are the real physical ones</li>
<li>finding good compromises between time, signal quality and ease of measurement</li>
<li>scanning mirror- versus stage coordinate system and reliable stitching</li>
<li>writing cross-platform software</li>
</ul>
<p>The general aspects listed above are not unique to the experiments and experimental setup, and could potentially be useful for others. But this thesis will also address issues directly associated to tissue micro arrays and the Leica SP8 microscope:</p>
<ul>
<li>adjusting z-plane for large area samples with micrometer precision</li>
<li>working around Leica software limitations</li>
</ul>
<p>Results on the dataset was positive/negative. Details on the result.</p>
<p>A proposal for further research with the same dataset is extracting more features from the images and use equivalent methods to find relationships to the clinic data. IF POSITIVE RESULT: Collecting tissue sample is a part of the standard procedure in breast cancer diagnosis at St. Olavs hospital, and one can do the analysis described in this thesis to further confirm or falsify the result.</p>
<h1 id="introduction">Introduction</h1>
<p>What to communicate: motivation, brief summary of chapters</p>
<p>With a population just above 5 million <a href="https://www.ssb.no/befolkning/statistikker/folkemengde">1</a>, three thousand women are diagnosed with breast cancer each year <a href="http://www.stolav.no/Pasient/Pasientforlop/Pasientforlop/Kreftsykdommer/Behandling-av-brystkreft/130731/">2</a> in Norway. This makes breast cancer the most common kind of cancer, affecting one of every eleventh woman. Luckily the cancer form is often treatable, and in 2012 there was 649 fatalities caused by breast cancer <a href="https://www.ssb.no/dodsarsak">3</a>. The diagnosis is an act of several steps, and currently contains the following at St. Olavs hospital:</p>
<ul>
<li>x-ray mammography</li>
<li>ultra sound screening</li>
<li>tissue sample(s)</li>
</ul>
<p>In particular, pathologists suggest that aggressiveness of a tumor is related to how fiber is aligned at the tumor peripheral. In example straight aligned fibers can be a sign that tumor cells have modified the stroma to promote spreading of cells. The alignment of fibers is a feature which can be extracted by image processing. Since several techniques to extract features is imaginable, supervised machine learning is practical for finding novel approaches.</p>
<p>From report - may use some of this: Over three million published articles on pubmed with keyword cancer shows the huge research effort for understanding, diagnosing and treating cancer diseases. The research focus is mainly on tumor cells, but a segment of interest which is increasing is research on tumor stroma as seen in figure 1.1.</p>
<p>Figure 1.1: Amount of published articles by year on different search terms. The search term tumor cells outnumber the others by two orders of magnitude. Note the logarithmic scale on y-axis.</p>
<p>Tumor stroma is the environment of cells, and it can be suppressing or supporting the function of the tumor cells. It is suggested that in the development of a tumor, the stroma is changing from being suppressive to supportive of the tumor cells [TODO REF].</p>
<p>In particular, collagen fiber is known to be altered in the surroundings of tumor cells under the development towards metastasis. One bio-marker for collagen fibers, is their alignment at the vincinity of the tumor, which may predict if a tumor is malignant. The fiber alignment can be used as a diagnosis tool for malignant tumor, and an article written at NTNU have studied collagen fiber alignment in a manual qualitative manner.</p>
<p>St. Olav hospital have breast tissue samples from 900 pasients along with clinical data. In total three samples per pasient, one sample inside, one sample at the boundary and one sample outside the tumor. The samples is laid in a matrix on a glass slide, each glass slide having about 130 samples. As microscope scanning and analysis of such a large data set is not straightforward, this project have explored possibilities for automating the process.</p>
<p>To be specific, this thesis will describe method and results for - parameters for obtaining quality SHG images - effective way to scan whole glass slides of 126 samples - machine learning and correlation to clinical data</p>
<blockquote>
<p>ML: En hoveddel i arbeidet har vært automatiseringen av TMA. Skrive noe om TMA og hvorfor automatisert analyse er nødvendig...skal lede opp til en beskrivelse av de tekniske utfordringene som er løst.</p>
</blockquote>
<h1 id="theory">Theory</h1>
<p>What to communicate: theory and details that are not obvious for understanding the rest of the text</p>
<blockquote>
<p>ML: I denne delen bør man primært ha med teori som er nødvendig for å forstå det som kommer i metodedelen. Altså ikke skriv for mye her før strukturen og innholdet er mer klart.)</p>
</blockquote>
<h2 id="leica-software">Leica software</h2>
<ul>
<li>socket</li>
<li>CAM</li>
<li>XML and scanning template (overview ST vs job ST)</li>
<li>wells and fields</li>
</ul>
<h2 id="image-processing">Image Processing</h2>
<ul>
<li>scikit-image, utils.ipynb, defaults in code blocks</li>
<li>OCR</li>
</ul>
<p>ORB and Ransac <a href="https://www.ssb.no/befolkning/statistikker/folkemengde">1</a>: https://peerj.com/articles/453/#p-1 ## Scanning microscope - Epi setup - scanning, descanned detectors</p>
<p>focal volume ## Nonlinear light interaction</p>
<h1 id="method">Method</h1>
<p>What to communicate: experimental setup to reproduce results, description of automatic process, limitations/obstacles specific to experimental setup, brief description of software modules in use</p>
<h2 id="microscope">Microscope</h2>
<p>The images has been taken with a Leica SP8 microscope using LAS X software version 1.1.0.12420 from Leica Microsystems CMS GmbH. Two lasers was in use, a pulsing Coherent laser and a continious LASOS argon laser. Full specifications of lasers are in <a href="#tbl:lasers">table </a>.</p>
<table>
<caption>Lasers {#tbl:lasers}</caption>
<colgroup>
<col width="14%" />
<col width="27%" />
<col width="58%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Brand</th>
<th align="left">Model</th>
<th align="left">Specifications</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><p>Coherent</p></td>
<td align="left"><p>Chameleon Vision-S</p></td>
<td align="left"><p>Modelocked Ti:Sapphire, wavelengths 690-1050 nm, 2500 mW, 80 MHz pulsing, <span class="math"> ≈ </span> 75 ps pulse width</p></td>
</tr>
<tr class="even">
<td align="left"><p>LASOS</p></td>
<td align="left"><p>LGK 7872 ML05</p></td>
<td align="left"><p>Argon Continious wave, wavelengths 458, 476, 488, 496 and 514 nm, 65mW</p></td>
</tr>
</tbody>
</table>
<p>The SP8 microscope has an inverted epi-setup, with four descanned detectors and four non descanned detectors. The descanned detectors use a prism along with adjustable mirrors so that specific wavelengths can be picked out in the signal, ranging from TODO. The descanned detectors was used with band pass filters of 525/50 nm and 445/20 nm. Two of the descanned detectors are behind the objective and two on opposite side of the objective behind a collector, which makes it possible to measure both backward and forward light.</p>
<h2 id="automated-scanning">Automated scanning</h2>
<p>Communicate: the procedure of automatic scanning</p>
<p>The automated scanning aims to lift the burden of manually labor and prevent errors in the imaging process by finding regions with the samples in an overview image. The process consists roughly of the steps:</p>
<ul>
<li>Take an overview image with low magnification</li>
<li>Segment the overview image</li>
<li>Allow user to confirm or adjust the segmentation</li>
<li>Scan each region</li>
</ul>
<p>Overview images was taken with a 10x air objective, equalized and stitched. The equalization step corrects uneven illumination and increases contrast for viewing purposes. To improve robustness of segmentation, a local bilateral population filter was applied to the stitched image before it is thresholded. Each separate region in the segmentation are sorted by their area size, small regions are excluded and the user can exclude or add regions if some of the samples are not detected. Row and column position of the regions are calculated by sorting them by their position in the image. A more detailed description follows.</p>
<h3 id="overview-images">Overview images</h3>
<p>Overview images was taken with an technique similar to bright-field microscopy except that the light source is a scanning laser. The laser in use was the argon laser in table  with 514 nm emission line, output power set to 2.48% and intensity to 0.10. Forward light was imaged using a 0.55 NA air collector with the non descanned detector having the 525/50 nm bandpass filter. Aperture and detector gain was adjusted so that the histogram of intensities was in the center of the total range without getting peaks at minimum and maximum values.</p>
<p>Zoom 0.75 and 512x512 pixels was chosen, which gives images of <span class="math"> ≈ </span> 1500 <span class="math"><em>μ</em></span>m (read more about resolution and image size in the discussion). After images is scanned, they are rotated 270 degrees, as Leica LAS store <em>.tif</em>-images with axes swapped in regards to the stage axes.</p>
<h4 id="uneven-illumination">Uneven illumination</h4>
<p><img src="figures/uneven_illumination_images_web.png" alt="(a) Image of glass slide only and no tissue for illustrating the uneven illumination. Dots are impurities in the sample. (b) Original image of sample. The white line is the row with least variance used for equalization. (c) Equalized version of (b). Note that (a), (b) and (c) are displaying values from 130 to 230 to highlight the intensity variation, colorbar is shown to the right." /> {#fig:illumination}</p>
<p>The uneven illumination in the experimental setup is illustrated in figure (a). By assuming the intensity variation in all pixels are following the slope of the background, equalization was done by dividing each row in the image by the normalized intensity profile of the background.</p>
<div class="sourceCode" caption="Equalizing an image" label="code:equalize"><pre class="sourceCode python"><code class="sourceCode python">equalized = img.astype(np.<span class="dt">float</span>)        <span class="co"># assure datatype have real division ability</span>
equalized -= images_minimum             <span class="co"># normalize</span>
equalized /= images_maximum - images_minimum
equalized /= intensity_profile          <span class="co"># equalize</span>
equalized[equalized &gt; <span class="dv">1</span>] = <span class="dv">1</span>            <span class="co"># clip values</span></code></pre></div>
<p>As seen in code listing  the image is first normalized. <code>images_minimum</code> and <code>images_maximum</code> is found by selecting the median of respectively minimum and maximum intensity of all images. By taking the median of all images one avoids outliers and gets the same normalization for all images. Similar technique could be used for normalizing the images after equalization, but clipping gave acceptable results. <code>intensity_profile</code> is a curve fit for one of the background rows. The background row was found by selecting the row with least variance (given that the image does have a row with background only). In figure (b) the row with least variance is indicated with a white line. The same intensity profile is used on all images, and it's fitted to a second degree polynomial to steer clear from noise as illustrated in (a).</p>
<p>The effect on pixel values can be seen in figure _intensities (b) and (c), where each dot represents a pixel value with increasing image x-position on the x-axis.</p>
<p><img src="figures/uneven_illumination_intensities_web.png" alt="(a) Intensities for the line with least variance of figure (b). The curve is fitted to a second degree polynom to supress noise. (b) Intensities for image in figure (b). Each dot represents a pixel. (c) Intensities for the equalized image in figure (c). Each dot represents a pixel. Note that the intensities is both spread across the whole intensity range (0-255) and the skewness is fairly straightened out." /> {#fig:illumination_intensities}</p>
<h4 id="stitching">Stitching</h4>
<p><img src="figures/stitching_comparison_web.png" alt="(a) Automatic stitching with Fiji is unreliable, as the image translation calculated by phase correlation is chosen without displacement constraints. (b) Using same overlap for all images gives negliable errors, here using the python package microscopestitching." /> {#fig:stitching}</p>
<p>Due to little signal in areas between samples, automatic stitching with correlation methods are prone to fail. To remedy this, the same overlap was chosen when stitching the overview image. Using the same overlap in this context gives reliable stitching with negligible errors. The overlap is chosen by calculating all overlaps with phase correlation and taking the median. The stitching was put in a python package and can be used as shown in code listing .</p>
<div class="sourceCode" caption="Stitching images with the python package *microscopestitching*." label="code:stitch"><pre class="sourceCode python"><code class="sourceCode python"><span class="ch">from</span> microscopestitching <span class="ch">import</span> stitch
<span class="ch">from</span> glob <span class="ch">import</span> glob

files = glob(<span class="st">&#39;path/to/images/*&#39;</span>)
images = []
<span class="kw">for</span> i, <span class="dt">file</span> in <span class="dt">enumerate</span>(files):
    <span class="co"># rectangle of 4 rows and len(files)//4 columns</span>
    row = i % <span class="dv">4</span>
    column = i // <span class="dv">4</span>
    images.append((<span class="dt">file</span>, row, column))

stitched_image = stitch(images)</code></pre></div>
<h4 id="segmentation">Segmentation</h4>
<p><img src="figures/segmentation_web.png" alt="Otsu thresholding of figure (b). (a) Otsu thresholding applied without any filters. Picks out dark areas, but disjointed, especially for brighter sample spots in bottom left. (b) Thresholding after a local bilateral population filter. Quite noisy in the background. (c) Thresholding after local bilateral population and local mean filter. Background noise is gone and sample spots are coherent." /> {#fig:segmentation}</p>
<p>As seen in figure (b), the samples at the edge are darker than the samples in the center. To improve this intensity variation, the overview image is filtered with a local bilateral population filter. The filter counts number of neighbour pixels that are outside a specified range. The effect of the filter is less computational demanding and somewhat similar to an entropy filter. Areas with low signal variation (the background) give low values and areas with high signal variation (the samples) give high values. To reduce noise after the bilateral population filter, a mean filter was applied. The size of structure elements was 9x9 pixels for both filters. Figure (a), (b) and (c) show how the segmentation is affected by the filters. Code for reproducing the steps are in code listing .</p>
<div class="sourceCode" caption="Filter and segment an image with local bilateral population and Otsu thresholding." label="code:segmentation"><pre class="sourceCode python"><code class="sourceCode python"><span class="ch">from</span> skimage.morphology <span class="ch">import</span> square
<span class="ch">from</span> skimage.filters <span class="ch">import</span> threshold_otsu
<span class="ch">from</span> leicaautomator.filters <span class="ch">import</span> mean, pop_bilateral

selem = square(<span class="dv">9</span>)
filtered = pop_bilateral(image, selem)
filtered = mean(filtered, selem)

threshold = threshold_otsu(filtered)
segmented = filtered &gt;= threshold <span class="co"># high values indicate signal</span></code></pre></div>
<p>After segmentation, regions was sorted by their area size and only the largest regions are kept. Row and column was calculated by sorting regions by position, measuring the distance between them and increment row or column number when there is a peak in the distance to previous region. The code can be seen in code listing  and figure  illustrate typical area size (a), position (b) and position derivative (c).</p>
<p><img src="figures/regions_area_and_position_web.png" alt="(a) Sorted region areas. Area size drops dramatically around region 125 according to number of samples on slide. (b) Regions sorted by position. There is a gap between the positions when row and columns are increasing. (c) X distance to previous region when regions are sorted by x-position. 14 peaks indicate that the image contain 15 columns. Note that x-axes in (a), (b) and (c) doesn&#39;t correspond, as the graphs are not sorted by the same attribute." /> {#fig:regions}</p>
<div class="sourceCode" caption="&quot;&quot;" label="code:regions"><pre class="sourceCode python"><code class="sourceCode python"><span class="ch">from</span> skimage.measure <span class="ch">import</span> label, regionprops

labels = label(segmented, background=<span class="dv">0</span>) <span class="co"># background=0: exclude background</span>
regions = regionprops(labels)           <span class="co"># measure region properties</span>
regions.sort(key=<span class="kw">lambda</span> r: -r.area)     <span class="co"># sort by area size, largest first</span>

max_regions = <span class="dv">126</span>
<span class="kw">if</span> <span class="dt">len</span>(regions) &gt; max_regions:
    regions = regions[:max_regions]     <span class="co"># only keep max_regions</span>

<span class="kw">for</span> r in regions:
    r.y, r.x, r.y_end, r.x_end = r.bbox <span class="co"># for convenience</span>

<span class="kw">for</span> direction in <span class="st">&#39;yx&#39;</span>:                  <span class="co"># same algorithm for row and columns</span>
    regions.sort(key=<span class="kw">lambda</span> r: <span class="dt">getattr</span>(r, direction))

    previous = regions[<span class="dv">0</span>]
    <span class="kw">for</span> region in regions:              <span class="co"># calc distance to previous region</span>
        dx = <span class="dt">getattr</span>(region, direction) - <span class="dt">getattr</span>(previous, direction)
        <span class="dt">setattr</span>(region, <span class="st">&#39;d&#39;</span> + direction, dx)
        previous = region</code></pre></div>
<p>The whole process of segmentation was done interactive as part of the python package <em>leicaautomator</em>, where settings can be adjusted to improve segmentation and regions can be moved, deleted or added with mouse clicks. The interface is shown in figure .</p>
<p><img src="figures/leicaautomator_web.png" alt="The process of segmentation in a graphical user interface. Regions 4,2, 11,7 and 14,1 might be adjusted by the user, all other regions are detected fairly well." /> {#fig:leicaautomator}</p>
<h4 id="calculate-stage-position-from-pixel-position">Calculate stage position from pixel position</h4>
<p>After regions was localized, pixel-size in meters was calculated by</p>
<p><br /><span class="math">$$ x_{resolution} = \frac{\Delta x}{\Delta X}. $$</span><br /> {#eq:resolution}</p>
<p>Here <span class="math">Δ<em>x</em></span> is displacement in pixels and <span class="math">Δ<em>X</em></span> is stage displacement in meters read from the overview scanning template in the experiment <code>AdditionalData/{ScanningTemplate}overview.xml</code> at XPath <code>./ScanningTemplate/Properties/ScanFieldStageDistanceX</code>. Left most left pixel was calculated by</p>
<p><br /><span class="math">$$ X_{start} = X_{center} - \frac{S_x \cdot x_{resolution}}{2}. $$</span><br /> {#eq:firstx}</p>
<p>In equation  <span class="math"><em>X</em><sub><em>c</em><em>e</em><em>n</em><em>t</em><em>e</em><em>r</em></sub></span> and <span class="math"><em>S</em><sub><em>x</em></sub></span> is respectively the stage position and number of pixels in the top left image of the overview scan. <span class="math"><em>X</em><sub><em>c</em><em>e</em><em>n</em><em>t</em><em>e</em><em>r</em></sub></span> was read from the overview scanning template at XPath <code>./ScanFieldArray/ScanFieldData[@WellX=&quot;1&quot;][@WellY=&quot;1&quot;][@FieldX=&quot;1&quot;][@FieldY=&quot;1&quot;]/FieldXCoordinate</code>. The stage x-coordinate for any pixel was then calculated by</p>
<p><br /><span class="math"><em>X</em> = <em>X</em><sub><em>s</em><em>t</em><em>a</em><em>r</em><em>t</em></sub> + <em>x</em> ⋅ <em>x</em><sub><em>r</em><em>e</em><em>s</em><em>o</em><em>l</em><em>u</em><em>t</em><em>i</em><em>o</em><em>n</em></sub>.</span><br /> {#eq:pos}</p>
<p>To be able to scan regions of different shape and size, a bounding box for the region was used to calculate the scanning area. Moving the stage to the boundary position will center the boundary in the image, and therefor start position of first image is calculated by</p>
<p><br /><span class="math">$$ X_{start} = X + \frac{\Delta X_{job}}{2}. $$</span><br /> {#eq:xstart}</p>
<p>Here, <span class="math">Δ<em>X</em><sub><em>j</em><em>o</em><em>b</em></sub></span> is stage displacement between images in the job scanning template. <span class="math"><em>X</em><sub><em>s</em><em>t</em><em>a</em><em>r</em><em>t</em></sub></span> will have an error of</p>
<p><br /><span class="math">$$ \epsilon = \frac{1}{2} (\Delta X_{job} - \Delta X_{img}), $$</span><br /> {#eq:xerror}</p>
<p>where <span class="math">Δ<em>X</em><sub><em>i</em><em>m</em><em>g</em></sub></span> is the total size of the scanned image. This was considered neglectible as <span class="math">Δ<em>X</em><sub><em>j</em><em>o</em><em>b</em></sub> ≈ Δ<em>X</em><sub><em>i</em><em>m</em><em>g</em></sub></span> and number of columns scanned was calculated by</p>
<p><br /><span class="math">$$ f_x = \lceil \frac{\Delta X}{\Delta X_{field}} \rceil. $$</span><br /> {#eq:enabledfields}</p>
<h4 id="scanning-each-region">Scanning each region</h4>
<p>To avoid unnecessary long stage movements between rows or columns, regions was looped through in a zick-zack pattern, given by their row and column position. For each region the scanning template was edited, the template was loaded and the scan was started through CAM. Single templates was used due to a Leica LAS software limitation; scanning templates with irregular spaced wells can not be loaded. Code listing  illustrates the process.</p>
<div class="sourceCode" caption="Scanning" label="code:automatedscan"><pre class="sourceCode python"><code class="sourceCode python"><span class="ch">from</span> leicascanningtemplate <span class="ch">import</span> ScanningTemplate
<span class="ch">from</span> leicaautomator <span class="ch">import</span> zick_zack_sort
<span class="ch">from</span> leicacam <span class="ch">import</span> CAM

cam = CAM() <span class="co"># instantiate connection to microscope</span>

<span class="co"># regions sorted as [r(1,1), r(1,2), r(2,2), r(2,1), r(3,1), r(3,2), ...]</span>
<span class="co"># here r(2,1) is region(col=2, row=1)</span>
regions = zick_zack_sort(regions, (<span class="st">&#39;well_x&#39;</span>, <span class="st">&#39;well_y&#39;</span>))

tmpl_path = <span class="st">r&quot;C:\Users\TCS-User\AppData\Roaming\Leica Microsystems\LAS X&quot;</span> + \
            <span class="co">r&quot;\MatrixScreener\ScanningTemplates&quot;</span> + <span class="st">&quot;</span><span class="ch">\\</span><span class="st">&quot;</span>
tmpl_name = tmpl_path + <span class="st">&#39;</span><span class="ot">{ScanningTemplate}</span><span class="st">leicaautomator&#39;</span>
<span class="kw">for</span> n, region in <span class="dt">enumerate</span>(regions):
    <span class="co"># alternate between tmpl_name0/1.xml, due to a</span>
    <span class="co"># bug LAS cannot load the same name twice</span>
    tmpl = ScanningTemplate(tmpl_name + <span class="dt">str</span>(n%<span class="dv">2</span>) + <span class="st">&#39;.xml&#39;</span>)

    tmpl.move_well(<span class="dv">1</span>, <span class="dv">1</span>, region.real_x, region.real_y)
    tmpl.write()

    cam.load_template(tmpl.filename)
 
    <span class="co"># do an autofocus</span>
    cam.autofocus_scan()
    cam.wait_for(<span class="st">&#39;inf&#39;</span>, <span class="st">&#39;scanfinished&#39;</span>)
         
    <span class="co"># run the scan job</span>
    cam.start_scan()
    <span class="co"># record output filename</span>
    region.experiment_name = cam.wait_for(<span class="st">&#39;relpath&#39;</span>)[<span class="st">&#39;relpath&#39;</span>]

    <span class="co"># continue with next region when scan is done</span>
    cam.wait_for(<span class="st">&#39;inf&#39;</span>, <span class="st">&#39;scanfinished&#39;</span>)</code></pre></div>
<h3 id="shg-images">SHG images</h3>
<p>SHG images was taken with a 25x/0.95 NA water objective. The pulsed infrared laser was set to 890 nm, intensity 20%, gain 40%, offset 80% and electro-optic modulator (EOM) on. Forward light was measured with non descanned PMT sensor behind a 0.9 NA air collector. Band pass filter in front of the detector was 445/20 nm and gain of detector was adjusted so that signal spanned the whole intensity range. Aperture was set to 24 (maximum).</p>
<p>A resolution of 1024x1024 pixels with 8 bit image depth was used. Frequency of scanning mirror was set to 600 lines/second.</p>
<h3 id="dapi-images">DAPI images</h3>
<p>TODO</p>
<h2 id="correlating-images-with-patient-data">Correlating images with patient data</h2>
<p><img src="figures/slidemap_web.png" alt="Top of slide map TP-1. Ids are not incrementing systematically and need to be registered to correlate samples to respective patients. Ids are inside circles and hard to read with OCR. First part of id is same as ID_deltaker in patient database, second number is sample number. There should be three samples for each patient." /> {#fig:slidemap}</p>
<p>Slide maps, seen in figure , and patient database was given by St. Olavs. As the slide maps contained circles, slide maps were filtered to remove all but text before it was read with OCR. The OCR text output was checked for errors programatically (id should be of correct format, id should increment, patients should be registered with correct slide in database column <code>TP_nr</code>, each patient should have three samples). OCR errors was fixed manually and other errors was recorded (see section <a href="#slidemaperrors">Slide map errors</a> in the appendix).</p>
<p>Every pasient id from the slide map was then saved to a stata database along with its slide number, row and column. Code listing  show how the clinical data was correlated with samples.</p>
<div class="sourceCode" caption="Get patient outcome of sample on TP-1 row 3 column 5." label="code:correlate"><pre class="sourceCode python"><code class="sourceCode python"><span class="ch">import</span> pandas <span class="ch">as</span> pd

<span class="co"># read databases</span>
locations = pd.read_stata(<span class="st">&#39;data/ids/locations.dta&#39;</span>)
clinical_data = pd.read_stata(<span class="st">&#39;data/clinic_data.dta&#39;</span>)

<span class="co"># position query</span>
condition = (locations.TP_nr == <span class="dv">1</span>) &amp; \
            (locations.TP_rad == <span class="dv">3</span>) &amp; \
            (locations.TP_kolonne == <span class="dv">5</span>)

<span class="co"># get patient id</span>
patient_id = locations[condition][<span class="st">&#39;ID_deltaker&#39;</span>]

<span class="co"># check exactly 1 patient registered at given row/col</span>
<span class="kw">assert</span> <span class="dt">len</span>(patient_id) == <span class="dv">1</span>

<span class="co"># clinical data query</span>
condition = clinical_data.ID_deltaker == patient_id.iloc[<span class="dv">0</span>]

<span class="co"># get outcome</span>
outcome = clinical_data[condition][<span class="st">&#39;GRAD&#39;</span>]</code></pre></div>
<h2 id="collection-of-shg-images">Collection of SHG images</h2>
<ul>
<li>alignment of z-plane</li>
<li>correlation with patient data (sample map and clinic data)</li>
</ul>
<h2 id="technical-details">Technical details</h2>
<h3 id="hardware-aspects">Hardware aspects</h3>
<ul>
<li>z-plane off by several hundreds of micrometer</li>
<li>piezo-holder tilted</li>
<li>slides not necessarily straight, coverslip placement</li>
<li>too much tilt: out of focus in one image</li>
<li>tolerated tilt and software autofocus: stitching when edge not from same physical area (especially thick samples)</li>
<li>signal variations and chosen optimum</li>
<li>collector 0.55 vs 0.9 when overview vs SHG</li>
<li>aperture not adjustable from software, resets when using occular</li>
<li>hard to get same conditions every time (might move to discussion: suggest using test sample routine along with image analysis)</li>
<li>rotation scanning mirror</li>
<li>stitch</li>
<li>finding angle with image registration / phase correlation</li>
<li>edge of image, intensity variation</li>
<li>zoom</li>
<li>correction for overview vs SHG</li>
<li>HyD shutdown too much light</li>
<li>HyD behind mirror might get less light, but still good signal</li>
<li>pinhole adjustment for HyD behind mirror to avoid bright spots?</li>
<li>reported resolution from LAS not same as stage movement</li>
<li>use image registration to calculate px-resolution</li>
<li>calibration of measurement-equiptment</li>
<li>what measurement to trust</li>
<li>outage and service</li>
<li>logging, feedback and communication between researchers</li>
<li>service contracts</li>
</ul>
<h3 id="leica-software-details">Leica software details</h3>
<p>The microscope software in use was Leica LAS X version TODO.</p>
<ul>
<li>loading template with variable positioned wells not working</li>
<li>offset first well will offset all wells</li>
<li>Properties/XStartPosition not used</li>
<li>no &quot;template-type&quot; property</li>
<li>must be loaded in GUI first time
<ul>
<li>through CAM opens GUI dialog &quot;Import?&quot;</li>
</ul></li>
<li>CAM only available after manually loading a template in GUI</li>
<li>GUI automation</li>
<li>loading modified template with same name</li>
<li>loading templates automatic goes to position and changes objective</li>
<li>crashes possible</li>
<li>trouble if using imersion objective</li>
<li>switching between AF / job in GUI will automatically switch objective without warning</li>
<li>trouble if using imersion objective</li>
<li>mix of 0-indexed and 1-index variables</li>
<li>files 0 indexed</li>
<li>cam 1 indexed</li>
<li>xml 1 indexed (TODO: verify)</li>
<li>GUI hangs if socket is not read</li>
<li>loading template should omit .xml from filename</li>
<li>saving template should not</li>
<li>not noted in documentation</li>
<li>&quot;templ.xml.xml not found&quot;</li>
<li>save template does not update with latest changes in GUI</li>
<li>XML does not read when missing return char &quot;&quot;</li>
<li>not in XML specification</li>
<li>z-position in template not read</li>
<li>z-position from CAM sometimes gives &quot;0&quot; instead of real position</li>
<li>adjusting x/y-coordinate on USB-control panel moves stage to zero or max position</li>
</ul>
<h3 id="software-development">Software development</h3>
<ul>
<li>Separate of concerns</li>
<li>modules and code reuse</li>
<li>publication of software packages and python ecosystem</li>
<li>leicacam: talking with microscope</li>
<li>leicascanningtemplate: modify templates</li>
<li>leicaexperiment: read, stitch, ome.tif experiments</li>
<li>microscopestitching: reliable stitching with phase corralation (remove outliers vs median)</li>
<li>leicaautomator: find regions to scan, unifies all of the above</li>
<li>python cross platform and compilation</li>
<li>heavy c/c++ dependency</li>
<li>miniconda</li>
<li>wheel packages</li>
</ul>
<p>Utilities (not specific thesis): - fijibin: automate fiji/imagej from python - ipynbcompress: compress images in ipython notebooks</p>
<blockquote>
<p>ML: Kan også skrive om spesifikke aspekter ved mikroskopsystemet som har muliggjort/begrenset/forhindret løsningene. All programvare som er utviklet bør omtales her, eventuelt med mer detaljer i et appendiks)</p>
</blockquote>
<h1 id="result">Result</h1>
<p>What to communicate: achievements and show-stopper/hard limitations</p>
<h2 id="segmentation-1">Segmentation</h2>
<div class="figure">
<img src="figures/thresholding_web.png" alt="Comparison of thresholding" />
<p class="caption">Comparison of thresholding</p>
</div>
<blockquote>
<p>ML: Resultat så langt: Kontroll via Python, segmentering, z-correction</p>
</blockquote>
<h1 id="discussion">Discussion</h1>
<p>What to communicate: discuss results, limitations, possibilities for improvement</p>
<blockquote>
<p>ML: Hvilke valg har blitt tatt, hva er viktig for neste bruker, hva er begrensninger, utviklingsmuligheter, pros/cons, hvor bra fungerer det....)</p>
</blockquote>
<h1 id="conclusion">Conclusion</h1>
<p>What to communicate: brief summary of the result and discussion, advice for further work</p>
<blockquote>
<p>ML: Automatic imaging and segmentation of TMA has been demonstrated)...and....</p>
</blockquote>
<h1 id="appendix">Appendix</h1>
<p>Leica LAS design: - user should be mainly in LAS - automating on the side as a supplement - load before CAM can be used - does not load all settings from XML</p>
<h2 id="slidemaperrors">Slide map errors</h2>
<pre><code> TP2, row  3, col  6 - pasient id missing in db: 66
 TP6, row  1, col  9 - pasient id missing in db: 222
 TP3, row  1, col  3 - id 68, wrong TP_nr in db: 3.0 != 2.0
 TP6, row  1, col  3 - id 209, wrong TP_nr in db: 6.0 != 4.0
 TP6, row  1, col  6 - id 221, wrong TP_nr in db: 6.0 != 5.0
TP22, row  2, col  6 - id 130, wrong TP_nr in db: 22.0 != 3.0
TP22, row  2, col  9 - id 244, wrong TP_nr in db: 22.0 != 5.0
TP22, row  3, col  3 - id 281, wrong TP_nr in db: 22.0 != 6.0
TP22, row  3, col  6 - id 296, wrong TP_nr in db: 22.0 != 6.0
TP22, row  3, col  9 - id 309, wrong TP_nr in db: 22.0 != 6.0
TP22, row  4, col  3 - id 318, wrong TP_nr in db: 22.0 != 6.0
TP22, row  4, col  6 - id 376, wrong TP_nr in db: 22.0 != 7.0
TP22, row  4, col  9 - id 396, wrong TP_nr in db: 22.0 != 8.0
TP22, row  5, col  3 - id 413, wrong TP_nr in db: 22.0 != 8.0
TP22, row  5, col  6 - id 449, wrong TP_nr in db: 22.0 != 9.0
TP22, row  5, col  9 - id 453, wrong TP_nr in db: 22.0 != 9.0
TP22, row  6, col  3 - id 487, wrong TP_nr in db: 22.0 != 10.0
TP22, row  6, col  6 - id 493, wrong TP_nr in db: 22.0 != 10.0
TP22, row  6, col  9 - id 525, wrong TP_nr in db: 22.0 != 10.0
TP22, row  7, col  3 - id 728, wrong TP_nr in db: 22.0 != 15.0
 TP3, row  9, col  6 - TP_nr not registered in db for ID_deltaker 140
 TP5, row  9, col  9 - TP_nr not registered in db for ID_deltaker 251
 TP9, row 10, col  9 - there should be 3 samples: [&#39;467a-1&#39;]
 TP9, row 11, col  3 - there should be 3 samples: [&#39;467b-1&#39;, &#39;467b-2&#39;]
 TP9, row 12, col  6 - there should be 3 samples: [&#39;471a-1&#39;, &#39;471a-2&#39;]
 TP9, row 12, col  9 - there should be 3 samples: [&#39;471b-1&#39;]
TP10, row  8, col  6 - there should be 3 samples: [&#39;507-1&#39;, &#39;507-2&#39;]
TP10, row 12, col  6 - there should be 3 samples: [&#39;525-2&#39;, &#39;525-3&#39;]
TP11, row 11, col  6 - there should be 3 samples: [&#39;566-1&#39;, &#39;566-2&#39;]
 TP3, row  1, col  3 - pasient id did not increment: [&#39;68-1&#39;, &#39;68-2&#39;, &#39;68-3&#39;]
                                                   &lt; [&#39;102b-1&#39;, &#39;102b-2&#39;, &#39;102b-3&#39;]
 TP4, row  1, col  3 - pasient id did not increment: [&#39;162a-1&#39;, &#39;162a-2&#39;, &#39;162a-3&#39;]
                                                   &lt; [&#39;163-1&#39;, &#39;163-2&#39;, &#39;163-3&#39;]
 TP6, row  1, col  3 - pasient id did not increment: [&#39;209-1&#39;, &#39;209-2&#39;, &#39;209-3&#39;]
                                                   &lt; [&#39;268-1&#39;, &#39;268-2&#39;, &#39;268-3&#39;]
TP11, row  6, col  3 - pasient id did not increment: [&#39;549-1&#39;, &#39;549-2&#39;, &#39;549-3&#39;]
                                                   &lt; [&#39;552-1&#39;, &#39;552-2&#39;, &#39;552-3&#39;]
TP22, row  2, col  6 - pasient id did not increment: [&#39;130-1&#39;, &#39;130-2&#39;, &#39;130-3&#39;]
                                                   &lt; [&#39;3067-1&#39;, &#39;3067-2&#39;, &#39;3067-3&#39;]</code></pre>
</body>
</html>
